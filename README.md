## 💻 Environment
![Postman](https://img.shields.io/badge/Postman-FF6C37?style=for-the-badge&logo=postman&logoColor=white) ![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white) ![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)![Gradle](https://img.shields.io/badge/Gradle-02303A.svg?style=for-the-badge&logo=Gradle&logoColor=white)
![GitHub Actions](https://img.shields.io/badge/github%20actions-%232671E5.svg?style=for-the-badge&logo=githubactions&logoColor=white) ![Hibernate](https://img.shields.io/badge/Hibernate-59666C?style=for-the-badge&logo=Hibernate&logoColor=white)
![JWT](https://img.shields.io/badge/JWT-black?style=for-the-badge&logo=JSON%20web%20tokens) ![YAML](https://img.shields.io/badge/yaml-%23ffffff.svg?style=for-the-badge&logo=yaml&logoColor=151515)


## 🚀 Development

![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white) ![Spring](https://img.shields.io/badge/spring-%236DB33F.svg?style=for-the-badge&logo=spring&logoColor=white) ![MySQL](https://img.shields.io/badge/mysql-4479A1.svg?style=for-the-badge&logo=mysql&logoColor=white)
![Redis](https://img.shields.io/badge/redis-%23DD0031.svg?style=for-the-badge&logo=redis&logoColor=white) ![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white) ![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)
![Terraform](https://img.shields.io/badge/terraform-%235835CC.svg?style=for-the-badge&logo=terraform&logoColor=white) ![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-000?style=for-the-badge&logo=apachekafka) ![ElasticSearch](https://img.shields.io/badge/-ElasticSearch-005571?style=for-the-badge&logo=elasticsearch) ![Grafana](https://img.shields.io/badge/grafana-%23F46800.svg?style=for-the-badge&logo=grafana&logoColor=white) ![Prometheus](https://img.shields.io/badge/Prometheus-E6522C?style=for-the-badge&logo=Prometheus&logoColor=white)



![image](https://github.com/user-attachments/assets/31486273-4021-4a76-9fe1-70d45fd112c2)



## 🗓️FitNus : 우리에게 딱 맞는 맞춤형 운동 플래너

## 📄 서비스/프로젝트 소개

## FitNus는 기존에 월 단위로 운동을 결제해야 했던 시스템을 벗어나 일 단위로 원하는 날짜에 원하는 운동을 일정으로 등록하고 예약하는 서비스입니다.

- 일정 관리가 되면서 경제적으로 저렴한 가격으로 제휴를 맺은 각종 운동 관련 센터들을 다양하게 이용할 수 있습니다.
- 같이 운동을 즐길 수 있는 모임을 찾기 쉬운 웹 어플리케이션입니다.

- 프로젝트 선정 이유
    - **운동 관련 키워드의 검색량이 증가 중인 상태 → 운동에 대한 관심도가 높아졌다.**
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/7d500133-faa0-450a-a80c-64999782034e/image.png)
    
    - **이왕이면 즐겁게 경험과 재미 추구, 헬시 플레저**
        - 과거에는 쾌락을 절제하거나 포기하면서 고통스럽게 운동을 했다면 이제는 즐겁고 효율적인 방법을 택해 ‘지속가능한 운동’을 추구
    - **“오늘 같이 뛸까요?” 크루’로 함께 즐긴다 → 모임 기능의 필요성**
        - 오프라인에서는 크루(Crew)라는 이름으로 함께 모여 러닝, 등산, 골프 등을 즐긴다. 이를테면, 러닝 크루의 경우 오픈 채팅방을 통해 모임을 공지하고, 정해진 날짜와 장소에 모여 달린 후 흩어지는 식
- 프로젝트의 필요성
    
    현재 원하는 운동을 즐기기 위해서는 월 단위로 결제하는 방식이 일반적이다. 복싱, 헬스, 클라이밍, 농구 등 다양한 운동을 하고 싶다면 각 운동에 대해 별도로 월 단위 결제를 해야 한다. 하지만 이러한 방식은 비용적인 부담을 크게 느끼게 만든다.
    
    사람들이 하고 싶은 운동은 많지만, 실제로 운동에 투자할 수 있는 시간은 제한적이다. 예를 들어, 4가지 운동을 등록했더라도 하루에 소화할 수 있는 운동은 평균적으로 2가지 정도에 불과하다. 그럼에도 불구하고, 여러 운동을 즐기고 싶다는 이유로 4개의 운동을 모두 월 단위로 등록하게 되면, 낸 비용이 아까워 억지로 모든 일정을 소화하려는 심리가 발생할 수 있다. 이는 최근 운동 트렌드인 *헬시 플레저*(Healthy Pleasure)와도 맞지 않게 된다.
    
    이러한 문제를 해결하기 위해, 원하는 날짜에 원하는 운동만 선택적으로 등록할 수 있는 프로그램이 있다면 비용 절감과 더불어 시간 관리의 부담을 줄일 수 있을 것이다. 이로 인해 더 유연하고 즐거운 운동 생활을 가능하게 할 수 있다는 점에서 해당 프로젝트의 필요성이 제기된다.
    
- 프로젝트 간단 예시
    
    사용자가 캘린더를 이용하여 원하는 센터의 운동을 본인의 일정에 등록(예약)하는 서비스입니다.
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/c908d094-49ce-4675-ab8d-9a663b617c13/image.png)
    
    사용자는 운동 일정뿐만 아니라 모임의 일정도 같이 관리할 수 있습니다.
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/f29ae050-e31c-4a99-95f5-2d9f0266ff6c/image.png)


## 🔑 KEY SUMMARY

- 일 단위 이용내역 기록 성능 개선
    
    조건: 배치 사이즈 = 1000


  - AWS의 Iac화 (using Terraform)
    
    **<before>**
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/95ad6685-1acf-4e55-84a9-3c23d89ef0cd/image.png)
    
    - 셋팅
        - AWS ECS, VPC 등은 셋팅할 때, 연관된 설정들을 다 셋팅 해줘야 비로소 만들 수 있음.
        - AWS VPC 삭제하려면, 연관된 라우팅테이블 - 서브넷 -네트워크까지 다 분리시켜야 VPC 삭제가 가능함.
    - 삭제
        - 삭제하다가 일부 빼먹는경우, 비용이 계속 첨부됨. 특히 NAT게이트웨이, ALB, Elastic ip 들은 어디에 연결되어 있지않고 혼자 존재하는경우 비용이 기하 급수적으로 부과됨
    
    ---
    
    **<After> #Infra as a code #AWS의 Ias화 #terraform사용**
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/69f97993-9601-4475-8993-8aff2eea0400/image.png)
    
    - 셋팅
        - terraform apply 입력 한번이면, 이 모든 셋팅이 한번에 가능함.
    - 삭제
        - terraform destroy 입력 한번이면, 이 모든 셋팅 삭제가 가능함.
- 스케줄 조회 성능 개선
    - 그래프
    
    ![스케줄 조회 그래프.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/21b4b455-4a51-485a-b118-95f1931f2895/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%A6%E1%84%8C%E1%85%AE%E1%86%AF_%E1%84%8C%E1%85%A9%E1%84%92%E1%85%AC_%E1%84%80%E1%85%B3%E1%84%85%E1%85%A2%E1%84%91%E1%85%B3.png)
    
- 사용자 위치 기반 센터 검색 성능 개선
    - 그래프
- 경매 입찰 동시성 제어 성능 비교
    
    ![Screenshot 2024-11-19 at 12.51.01 am.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/694577c0-fc7f-4e94-9d33-082c06f167fb/Screenshot_2024-11-19_at_12.51.01_am.png)
    
    ![output (2) (1).png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/b43c341d-9e40-4b63-ad3c-5480944017b6/output_(2)_(1).png)
    
- 일정 등록(예약) 동시성 제어 성능 개선
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/9ef5d073-3930-40bd-8f14-a04db46e61f8/image.png)
    

## ⚙️ 인프라 설계

![11.19일 Ver6.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/639e09d3-1a49-4791-8d42-6d212545b925/11.19%E1%84%8B%E1%85%B5%E1%86%AF_Ver6.png)



## 🧨 주요 기능

- 일정 등록 및 관리
    - 사용자는 다양한 운동들을 직접 결합하여 캘린더에 스케줄을 등록 및 수정할 수 있습니다.
    - 런닝, 클라이밍 등 같이 하고 싶은 운동 관련 모임을 스케줄에 등록할 수 있습니다.
- 알림
    - SSE를 통해 실시간으로 클라이언트에게 전송됩니다.
        - 유저가 모임 신청 시 모임장에게 알림이 전송됩니다.
        - 스케줄에 등록된 운동 또는 모임 일정 1시간전에 알림이 전송됩니다.
- 실시간 경매
    - 일정 기간 동안 열리는 경매에 사용자가 쿠폰을 사용하여 입찰할 수 있습니다.
    - 경매가 끝나는 시점 최고가 입찰을 한 사용자에게 입찰가만큼 쿠폰이 차감됩니다.
    - SSE를 통해 실시간 최고 입찰가 & 경매 결과를 클라이언트에게 전송합니다.
- 카카오페이 결제
    - 카카오 페이 api를 연동하여 결제를 구축하였습니다.
    - 개당 1000원에 혹은 번들 (20만원에 220개 30만원에 345개) 로 구매 가능합니다.
- 정산
    - 일 단위 센터이용내역 기록: 매일 새벽 1시에 센터 이용내역을 별도의 테이블에 기록합니다.
    - 월 단위 정산: 스프링 배치와 스케쥴링을 사용하여 매월 1일에 정산합니다.
    - 월 단위 결제내역 정산: 사용자의 결제내역을 정산하여 월 단위 정산과 검증합니다.
- 위치 기반 검색
    - Redis 캐싱과 Elasticsearch를 사용하여 센터 검색 성능을 비교하여 더 나은 방안을 선택하였습니다.


## 🚀 적용 기술

- **프레임워크**: Spring Boot, Spring Batch
- **데이터베이스**: MySQL, Redis
- **메세지 브로커**: SSE, Kafka
- **검색 엔진**: Elasticsearch
- **인증/보안**: Spring Security, JWT
- **배포 환경**: AWS (EC2, RDS, ECR, VPC, ELB, AutoScaling), Docker, GitHub Actions, Terraform
- **아키텍처**: 모듈화 기반 설계
- **외부 API**: 카카오페이, 카카오로그인, 카카오지도
- **모니터링 도구**: Grafana, Prometheus
- **고가용성**: Redis Sentinel


## 기술적 의사 결정

- 경매
    
    ### 기술적 접근
    
    1. **Kafka를 통한 입찰 이벤트 비동기 처리**:
        - 사용자가 입찰할 때마다 입찰 이벤트를 Kafka 토픽에 비동기로 전송.
        - 여러 Consumer가 동시에 이벤트를 처리하고, 최고 입찰가를 유지.
        - 경매 종료 후 최고 입찰가와 낙찰자를 결정하여 결과를 저장.
    2. **최고 입찰가 실시간 업데이트**:
        - 최신 입찰가 정보를 모든 유저에게 실시간으로 전송하기 위해 Server-Sent Events (SSE)를 사용.
        - Kafka Consumer가 최고 입찰가를 업데이트할 때마다 SSE를 통해 클라이언트에 푸시.
    3. **데이터 저장**:
        - Kafka는 단기적인 메시지 저장만을 제공하므로, 영구적으로 보관할 데이터는 데이터베이스에 저장.
        - `Auction` 및 `User` 엔티티를 통해 최고 입찰가와 낙찰자 정보를 저장.
        
        | 방법 | 장점 | 단점 |
        | --- | --- | --- |
        | Kafka | 데이터 분산 처리를 통해 빠른 비동기 입찰 이벤트 관리 가능, 파티션 분산을 통해 대량 트래픽 처리 가능 | 데이터 영구 저장은 지원하지 않음. 데이터베이스 백업이 필요한 데이터는 별도로 관리 필요 |
        | Kafka + 데이터베이스 | 영구 저장이 필요한 데이터는 데이터베이스에 저장, 이벤트 기반의 비동기 처리로 성능 최적화 가능 | 시스템 복잡도가 증가하며, 데이터베이스와 Kafka 간 동기화에 신경 써야 함 |
- 정산
    
    ## 목표
    
    아주 많은 데이터인 일정 예약 기록을 효율적으로 빠르게 처리하는 것도 중요하지만 작업을 어디까지 진행했는지 계속해서 파악할 수 있게하여 데이터를 중복으로 처리하는 것도 방지하고 데이터의 일관성을 지키는 정산 기능을 구현해야 한다. 
    
    ## 정산의 필요성
    
    정산은 센터의 이용 내역과 그에 따른 수익 및 수수료 정보를 체계적으로 관리하고, 실제 지급되는 정산금액을 기록하고 받을 수 있도록 도와주는 중요한 기능이다. 이를 통해 신뢰성있는 정산 조회 기능 또한 제공되어야 한다.
    
    ## 요구사항
    
    - 정산 기능은 아주 많은 데이터를 처리하는 중간에 프로그램이 멈출 수 있는 상황을 대비해 안전장치를 마련해야 함
    - 정산 기능은 데이터를 효율적으로 빠르게 처리하는 것도 중요하지만, 작업을 어디까지 진행했는지 계속해서 파악이 가능하며 이미 했던 일을 중복해서 하지 않게 파악할 수 있어야 한다.
    
    ## 기술 선택 이유
    
    **선택한 기술: 스프링 배치**
    
    1. 스프링 배치는 대용량 데이터를 청크 단위로 처리할 수 있고 각 청크가 처리될 때마다 커밋하여 메모리 사용을 최적화 할 수 있다.
    2. 실패한 배치 작업을 중단된 지점부터 retry하거나 skip할 수 있다.
    3. 배치 작업의 진행 상태와 소요 시간 등의 정보를 제공받을 수 있다.
    4. 트랜잭션 관리를 지원하여 데이터의 일관성을 유지 가능하다.
    5. Spring Scheduler 또는 Quartz와 같은 것들을 트리거로 하여 자동화 할 수 있다.
- 정산의 트리거
    
    ## [기능 설명]
    
    정산은 센터의 이용 내역과 그에 따른 수익 및 수수료 정보를 체계적으로 관리하고, 실제 지급되는
    정산금액을 기록하고 받을 수 있도록 도와주는 중요한 기능입니다. 이를 통해 신뢰성있는 정산
    조회 기능 또한 제공되어야 하므로 정산 기능을 구현했습니다.
    
    ## [주요 로직]
    
    1. 일 단위 수익 정산
        - 매일매일 센터를 이용한 사람과 어떤 종목, 어떤 시간대에 센터를 이용했는지를 기록
        - 기록된 정보는 변하지 않음
        - 일 단위 수익 정산은 기록을 위한 기능이지 실제로 일 단위로 정산이 되는 것은 아님
    2. 월 단위 센터 수익 정산
        - 매월 1일에 월 단위 정산을 실시
        - 월 단위 정산은 한 달간 총 수익과 수수료를 계산
        - 정산된 대금이 정산 결과 테이블에 저장되기 전에 이용내역의 정보를 통한 계산 내용과
        일치하는지 검증 후 저장
    3. 월 단위 서비스 수익 정산
        - 매월 1일에 사용자의 결제 내역을 통한 정산을 수행
        - 결제 내역을 통한 매출을 합산하고 월 단위 센터 수익 정산 결과를 이용해 모든 센터에
        지급할 대금을 대조하여 적자가 없는지 확인
    
    ## [배경]
    
    정산 기능을 스프링 배치로 구현하였지만 스프링 배치 프레임워크 자체에는 어떻게 이 배치 Job을
    실행할 것인가에 대한 스케쥴러 기능이 내장되어 있지 않았고 스프링 스케쥴러와 함게 사용되도록
    의도되어있는 느낌이 들었습니다. 따라서 트리거의 역할을 할 스케쥴러 중 어떤 것을 선택할 것인지
    의사결정을 할 필요가 있었습니다.
    
    ## [요구사항]
    
    1. 스프링 배치 작업을 실행할 시점을 제어할 수 있어야 한다.
    2. 스프링 배치 작업은 별도의 모듈로 이미 분리가 되어 있는 단일 서버 환경이므로 분산 처리는
    필요 없다.
    3. 작업에 대한 기록은 meta 테이블에서 기록이 되고 있으므로 스케쥴 작업에 대한 기록을 따로
    저장할 필요는 없다.
    4. 정산 기능은 주로 일정테이블의 기록을 이용 내역 테이블로 복제하거나 이용 내역 테이블을
    조회하여 센터에 지급할 대금을 계산하는 등의 간단한 작업이다.
    
    ## [선택지]
    
    1. Spring Scheduler
        - 스프링 스케쥴러는 스프링 프레임워크에서 기본적으로 제공하는 작업 예약 도구이며 스프링 부트 스타터에 기본적으로 내장되어 있다.
        - @Scheduled 어노테이션으로 간단하게 구현이 가능하다.
        - 단일 스레드로 동작한다.
    2. Quartz Scheduler
        - 쿼츠 스케쥴러는 Java 기반의 오픈소스 Job Scheduling 라이브러리 이며 간단한 interval과
        Cron 표현식 모두를 지원한다.
        - 클러스터링을 지원하며 수천 개의 작업을 동시에 실행하는 것이 가능하다.
    
    ## [의사결정/사유]
    
    - 일 단위 센터별 이용내역 처리와 월 단위 센터별 지급할 대금을 계산하는 단순한 작업이고,
    정산서버는 다중 서버가 아니므로 Quartz의 큰 이점 중 하나인 클러스터링도 사용할 수 없을
    것으로 보여서 Spring Scheduler를 사용하여 구현하는 것이 합리적으로 보임
    - 쿼츠 스케쥴러에 데이터 베이스에 작업 상태를 저장할 수 있지만 이 부분은 스프링 배치로
    보완가능
    
    그렇다면 스프링 배치 + 스프링 스케쥴러가 아니라 쿼츠 스케쥴러 단일로만 사용하면 안되나?
    
    → 쿼츠 스케쥴러는 데이터 처리 기능이 내장되어 있지 않기 때문에, 대량의 데이터를 처리하기
    위해 별도의 데이터 처리 로직을 개발해야함
    
    ### [회고]
    
    기술의 장단점
    
    1. **Spring scheduler 장단점**
    장점:
        - 스프링 프레임워크에 통합되어 있어 설정이 간단하고, 코드 내에서 직접 사용가능
        - 별도의 라이브러리 설치가 필요 없으며, 스프링 컨텍스트에서 자동으로 관리
        - 스프링 배치와 자연스럽게 통합되어 작업을 쉽게 관리 가능
        
        단점:
        
        - 복잡한 스케줄링 요구 사항을 지원하는 데 한계가 있을 수 있음
        - 여러 인스턴스에서 동작할 경우, 작업의 중복 실행을 방지하는 데 어려움이 있을 수 있음
    2. **Quartz Scheduler**
    장점:
        - 크론 표현식 지원, 복잡한 트리거 조건, 작업 실행 간격 설정 등 다양한 스케줄링 옵션을
        제공
        - 여러 서버 인스턴스에서 작업을 분산 처리할 수 있어, 안정성과 확장성이 뛰어남
        - 데이터베이스에 작업 상태를 저장할 수 있어, 서버 재시작 후에도 작업을 재개 가능
        - 다양한 API를 제공하여 복잡한 스케줄링 요구에 쉽게 대응할 수 있음
        
        단점:
        
        - 초기 설정과 사용이 다소 복잡할 수 있으며, 추가적인 의존성이 필요
        - 스프링 스케줄러에 비해 더 많은 자원을 소모할 수 있음
        
    - 다시 시도한다면?
    젠킨스에 대해 공부한 다음 젠킨스를 트리거로서 사용할 것 같습니다.
        
        젠킨스를 트리거로 할 때의 장점:
        
        1. 실행 이력 관리
            - 배치 작업의 시작 이력이 자동으로 기록됨
            - 실행 로그 확인 용이
        2. 유연한 관리
            - 소스 코드 수정 없이 스케줄 시간 변경 가능
            - 테스트를 위한 즉시 실행 가능
        3. 모니터링
            - 실행 결과 확인 용이
            - 실패 시 이메일이나 슬랙으로 알림 설정 가능
        
        유연한 관리와 모니터링 측면에서 젠킨스가 좀 더 매력적으로 느껴집니다.
        
- 검색
    1. **센터 검색시 위치정보 전달**
        1. 해당 기능이 필요한 이유
            1. 사용자의 위치를 기반으로 검색 정보가 전달되지 않는다면 불필요한 정보를 전달받을 가능성이 있습니다. 이를 방지하기 위해 사용자의 위치를 기반으로 주변에 있는 센터의 정보를 전달하는 기능이 필요하다고 생각했습니다.
        2. Elasticsearch를 선택한 이유
            1. **빠른 검색 성능**: 대규모 데이터셋에서 **빠른 거리 계산** 및 **위치 기반 검색**을 처리할 수 있습니다.
            2. **확장성**: 수평 확장이 용이하며, 큰 규모의 데이터를 처리할 수 있습니다.
            3. **Geo-point** 형식을 사용해 인덱싱하고, **Geo-distance query**를 통해 빠른 위치 기반 검색을 할 수 있습니다.
                1. **Geo-point** 형식은 **위치 정보를 저장**하기 위한 **Elasticsearch**의 데이터 타입으로 위도와 경도를 사용해 위치를 정의할 수 있습니다.
                2. **Geo-distance query**는 **Elasticsearch**에서 제공하는 **위치 기반 쿼리**로, 위도와 경도에서 **주변의 다른 위치들**을 **거리** 기준으로 검색할 수 있는 기능입니다. 이 쿼리는 **사용자 위치**를 기준으로 일정 **반경 내의 데이터**를 찾아주는 데 사용됩니다.
            4. **복합 쿼리 지원**: **위치**와 **다양한 필터**를 결합한 복잡한 쿼리도 효율적으로 처리할 수 있습니다.
                1. Elasticsearch를 사용한다면 다른 쿼리와 결합하여 보다 나은 검색 결과를 처리할 수 있는 경험을 해볼 수 있습니다.
- 지도
    
    ### **Redis Geospatial vs MySQL Geometry를 이용한 위치 기반 검색 기능**
    
    ### **1. Redis Geospatial**
    
    **장점:**
    
    - **빠른 성능**: 메모리 기반의 저장소로, 위치 데이터 조회 시 매우 빠른 응답 시간 제공.
    - **실시간 반경 검색**: `GEORADIUS`, `GEOSEARCH` 명령어를 사용해 실시간으로 반경 내 위치를 빠르게 검색 가능.
    - **간단한 캐싱**: 위치 데이터를 캐싱하여, 서버 부하를 줄이고 빠른 조회가 가능함.
    - **확장성**: Redis는 분산 환경에서 확장성이 뛰어나, 많은 양의 위치 데이터를 안정적으로 처리 가능.
    
    **단점:**
    
    - **영속성 부족**: Redis는 메모리 기반이므로, 데이터 손실 가능성이 있음. 영구 저장을 위해서는 백업 설정이 필요.
    - **복잡한 쿼리 제한**: 복잡한 위치 기반 쿼리(예: 다각형 검색 등)는 지원하지 않음.
    - **데이터 구조 제한**: 위치 데이터 외에도 다양한 메타데이터를 함께 저장하기 어려움.
    
    **사용 사례:**
    
    - **실시간 반경 검색**: 사용자의 위치 기반으로 인근 센터를 실시간으로 조회해야 하는 경우.
    - **캐싱 기능 활용**: 자주 조회되는 위치 데이터를 캐싱하여 성능 향상이 필요한 경우.
    
    ### **2. MySQL Geometry**
    
    **장점:**
    
    - **영구 저장**: MySQL의 공간 데이터 타입(`POINT`, `POLYGON`)을 사용해 위치 데이터를 영구 저장 가능.
    - **공간 인덱스 지원**: `SPATIAL INDEX`를 통해 대규모 위치 데이터에서도 빠른 조회 가능.
    - **복잡한 위치 기반 쿼리 가능**: `ST_Distance_Sphere`와 같은 함수를 사용해 반경 검색, 거리 계산, 다각형 내 검색 등이 가능.
    - **데이터 안정성**: 데이터베이스에 저장되므로, 영속성과 데이터 보존이 보장됨.
    
    **단점:**
    
    - **속도 제한**: 메모리 기반의 Redis에 비해 조회 속도가 느릴 수 있음.
    - **복잡한 설정**: 공간 인덱스 설정이 다소 복잡할 수 있으며, 대규모 데이터에서는 쿼리 최적화가 필요.
    - **확장성 제한**: MySQL 단일 인스턴스에서 처리할 수 있는 트래픽의 한계가 있을 수 있음.
    
    **사용 사례:**
    
    - **장기적인 데이터 보관**: 위치 데이터를 영구적으로 저장하고, 정확한 위치 계산이 필요한 경우.
    - **복잡한 위치 쿼리**: 다각형 내 검색이나 거리 계산과 같이 복잡한 위치 기반 쿼리가 필요한 경우.
    
    ### 👉 redis를 선택한 이유
    
    - **빠른 실시간 검색 성능**과 **간단한 반경 검색 기능**, 그리고 **캐싱을 통한 서버 부하 감소** 때문
        - 저희 프로젝트의 현재 위치 기반 검색 기능에서는 단순한 반경 검색이 주된 요구사항. MySQL Geometry는 복잡한 위치 기반 쿼리(다각형 검색 등)에 강점이 있지만, 이 프로젝트에서는 필요하지 않으므로 Redis의 간단한 반경 검색 기능이 적합.
    - 또한, Redis의 확장성은 대량의 위치 데이터를 안정적으로 처리할 수 있어 요구사항에 적합
- CI/CD
    
    ### 1. CI/CD 및 인프라 구축
    
    **선택 이유:** CI/CD 구축을 통해 개발 주기를 단축하고 자동화된 테스트 및 배포를 통해 품질을 보장하며, 빠르게 피드백을 받아 수정할 수 있습니다.
    
    - **장점**
        - **자동화된 배포:** Github Actions를 활용해 CI/CD 파이프라인을 구축함으로써 코드 변경 시 자동으로 빌드, 테스트, 배포가 가능해져 개발 주기가 빨라집니다.
        - **일관된 품질 유지:** 테스트 자동화를 통해 코드 품질을 일정 수준으로 유지하고, 버그를 사전에 발견할 수 있습니다.
        - **확장성**: 멀티 모듈 프로젝트에 맞춰 각 모듈의 독립적 배포 및 확장이 가능하며, 모듈화된 구조로 인프라를 유연하게 확장할 수 있습니다.
    - **단점**
        - **초기 설정의 복잡성:** CI/CD 파이프라인을 설계하고 설정하는 과정이 복잡하며, 특히 멀티 모듈에 맞게 설정 시 초기 시간이 많이 소요될 수 있습니다.
    - 다른방법과 비교
        - jenkinsen : 성능적 측면에서는 비슷하나, 설정용이성 측면에서 깃헙액션이 좀 더 좋다. 가장 크게 고려한 점은 젠킨슨은 온프레미스 방식이기 때문에 팀원에서 한명만 관리가 가능하다. githubActions는 팀원들 모두가 사용할 수 있기 떄문에 githubActions를 선택했다.
    
    ### 2. AWS
    
    **선택 이유 :** AWS는 다양한 서비스를 제공해 다양한 인프라 요구사항을 충족하며, 글로벌 인프라를 통해 확장성과 가용성이 높은 서비스를 제공할 수 있습니다.
    
    - **장점**
        - **확장성 및 가용성 :** ELB, Autoscaling 등을 사용하여 트래픽 변화에 따라 시스템을 자동으로 확장 및 축소할 수 있습니다.
        - **보안 관리의 용이성:** IAM을 통해 서비스별 세분화된 권한 관리가 가능하여 보안 위험을 줄일 수 있습니다.
        - **모니터링 기능**: Cloudwatch를 통해 시스템 상태를 실시간으로 모니터링하고, 장애 발생 시 즉시 대응이 가능합니다.
    - **단점**
        - **비용 부담:** AWS는 사용량에 따라 비용이 증가할 수 있으며, 서비스 구성이 복잡할수록 비용이 예상보다 높아질 수 있습니다.
    - 다른방법과 비교
        - 1.Kubernetes : 아이러니하게도, 서버4대 필요한 Kubernetes보다 ECS나 EKS가 더 저렴합니다. 비용적 측면에서 ECS쓰는 것이 쿠버네티스보다 이득이어서 선택하게 되었습니다.
    
    ### 3. 도커 컨테이너 및 Elastic Container Service
    
    **선택 이유 :** 컨테이너 기반으로 애플리케이션을 배포함으로써 환경 격리를 유지하고, 서비스 의존성을 독립적으로 관리할 수 있어 DevOps 환경에 적합합니다.
    
    - **장점**
        - **환경 격리 :** Spring, Redis, Config-server를 각각 컨테이너로 구성하여 독립적 운영이 가능하며, 환경별 의존성 문제를 줄일 수 있습니다.
        - **확장성 :** ECS를 통해 서비스를 컨테이너 별로 관리할 수 있으며, 확장 시에도 유연하게 대응할 수 있습니다.
        - **이식성** : 개발 및 운영 환경의 일관성을 보장하여 배포에 필요한 설정을 최소화할 수 있습니다.
    - **단점**
        - **자원 소모 :** 컨테이너 구동 시 시스템 리소스를 많이 소모할 수 있어 자원 관리가 필요합니다.
    
    ### 4. Config-server
    
    **선택 이유 :** 환경별 설정 관리를 통합하여 운영 효율성을 높이고, 환경 설정의 통일성을 확보하기 위해 선택되었습니다.
    
    - **장점**
        - **중앙 집중식 관리 :**  config-server를 사용하면, 운영 및 개발 환경에서 통합된 환경 변수 관리가 가능하여 환경별 설정 파일을 일관되게 관리할 수 있습니다.
        - **형상 관리 :** GithubActions의 secrets로 관리하던 환경변수들은 언제 업데이트 되었는지, 현재 value 값에 뭐가 들어있는지 확인할 수 없지만, config-server는 하나의 git private 프로젝트로 관리하기 때문에, 보안도 챙기면서, 형상관리까지 가능합니다.
    - **단점**
        - **단일 장애점** : Config-server가 중단될 경우 모든 서비스의 설정 관리에 영향을 줄 수 있어 안정적 운영이 중요합니다.
        - **설정 복잡성**: 환경별로 다른 설정을 관리하다 보면 설정이 복잡해질 수 있습니다.
    - 다른 방법과 비교
        - .env : 로컬에서 관리하는 방법이다. .gitignore써서 보안적 문제는 해결할 수 있으나, 배포를하기 시작하면, 운영/개발 환경 환경변수를 githubActions(secrets)/.env 두 곳에서 관리해야하니 통합관리가 어렵습니다.
            - 1. 통합관리 : .env파일보다 config-server가 이점이 있습니다.
            - 2. 형상관리 : 배포 환경변수는 gitactions에서 관리해야하는데, 등록된 value값을 볼 수 없으니 관리가 어렵다. 그러나 config-server는 형상관리까지 가능하다.
        
    
    ### 5. Terraform
    
    **선택 이유 :** AWS 인프라 관리를 코드화하여 자동화 및 버전 관리를 가능하게 하여 효율성을 높이기 위해 Terraform을 도입했습니다.
    
    - **장점**
        - **자동화된 인프라 구축:** AWS의 자원을 코드로 관리하여 인프라를 자동으로 프로비저닝하고 유지할 수 있습니다.
        - **버전 관리:** IaC 도입으로 인프라의 변경 사항을 Git과 같은 버전 관리 시스템을 통해 관리할 수 있어, 변경 사항을 추적하기 용이합니다.
        - **재사용성**: 여러 환경에서 동일한 코드로 인프라를 구축할 수 있어 효율적입니다.
    - **단점**
        - **초기 설정 및 학습 곡선:** Terraform의 코드 작성과 구조 이해에 시간이 필요하며, 초기 설정에 많은 노력이 필요합니다.
        - **복잡한 관리:** 인프라 변경 시 종속성 문제로 인해 예상치 못한 결과가 발생할 수 있어 관리가 복잡할 수 있습니다.
    
- 모듈화의 필요성
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/f2daecdd-de3f-4327-86b3-c5b493de9a5e/image.png)
    
    기존의 프로젝트는 단일 모듈로 구성되어 있었다. 점차 프로젝트 규모가 커지면서 모든 코드가 하나의 파일이나 프로젝트에 포함되어 있어 복잡성이 증가하게 되었다. 시간이 지날수록 코드의 양은 늘어가고 클래스를 바로 찾기가 쉽지 않았으며 프로젝트를 빌드하는 시간도 오래걸려 한국인은 참지 못하는 상황이 되었다.
    
    이대로 기능이 더 추가된다면? 조금이라도 더 복잡해진다면? 유지보수는 정말 힘들어질 수도 있다는 생각이 들었다. 아직 크게 복잡하지 않은 상황에서 재설계의 필요성을 느꼈다. 
    
    가장 큰 문제점은 Auction과 Schedule, Notification은 대용량 트래픽이 발생할 수 있다는 점이다.
    
    배포할 때 오토스케일링을 적용할 예정이었기 때문에 대용량 트래픽이 발생할 경우 단일 모듈은 오토스케일링 그룹으로 묶여 Scale Out 되어 규모를 늘리게 되는데 
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/59ee0dc4-2c87-4ac4-914e-cd36db50a613/image.png)
    
    모든 도메인이 같이 Scale Out 되어 버린다.
    
    이 경우 문제점은 Batch의 경우 관리자 기능만 존재하여 트래픽이 몰릴 이유가 없고 User와 Payment 같은 경우도 사용량이 적을 것으로 생각이 된다. 또한 Auction은 특정 기간에만 열리는 이벤트 개념의 도메인이다. 
    
    즉, Scale Out이 불필요한 도메인까지 같이 규모가 늘어나기 때문에 더 비싼 서버를 사용해야하고 이는 효율성이 좋지 못하며 유연성이 떨어진다. 또한 하나의 도메인에 문제가 생길 경우 전체 도메인에 영향을 끼칠 수 있기 때문에 이를 조금이라도 개선하기 위해 멀티 모듈로 구조를 바꾸기로 결정하였다.
    
    **그 외의 멀티 모듈의 장점:**
    
    - 특정 모듈의 변경이나 업데이트가 전체 프로젝트에 미치는 영향을 최소화할 수 있음
    - 각 모듈을 독립적으로 개발하고 테스트할 수 있어 개발 속도와 품질이 향상됨
    - 버그가 발생했을 때 전체 시스템이 아닌 해당 모듈만 검토하면 되어 디버깅이 용이함
    - 수정된 모듈만 리빌드하면 되어 빌드 시간이 단축됨
    - 각 모듈은 독립적으로 빌드, 테스트, 배포가 가능
    - 프로젝트가 성장함에 따라 새로운 모듈을 추가하거나 기존 모듈을 확장하기 쉬움
    - 각 모듈이 필요한 최소한의 의존성만 가질 수 있어 시스템의 복잡도를 낮출 수 있음
    
    ## 그렇다면 어떻게 모듈화를 해야 하나?
    
    ### 1. 레이어별 모듈화 (Layered Modularization)
    
    레이어별 모듈화는 시스템을 여러 개의 레이어로 나누어 각 레이어가 특정한 역할을 수행하도록 구성하는 방식이다. 일반적으로 프레젠테이션 레이어, 비즈니스 로직 레이어, 데이터 액세스 레이어 등으로 나뉜다.
    
    - **계층 구조**: 각 레이어는 상위 레이어에 의존하며, 하위 레이어에 의존하지 않는다.
    - **명확한 역할 분리**: 각 레이어는 특정한 책임을 가지며, 이를 통해 코드의 가독성과 유지보수성을 높인다.
    - 장점:
        - 유지보수 용이
        - 테스트 용이
        - 재사용성
        - 명확한 구조
    - 단점:
        - 성능 저하: 레이어 간의 호출이 많아질 경우, 성능 저하가 발생할 수 있음
        - 복잡성 증가: 레이어가 많아질수록 시스템의 복잡성이 증가할 수 있음
        - 과도한 추상화: 레이어가 지나치게 세분화되면, 오히려 코드가 복잡해질 수 있음
    
    ### 2. 도메인별 모듈화 (Domain-Driven Modularization)
    
    도메인별 모듈화는 비즈니스 도메인에 따라 시스템을 모듈화하는 접근 방식이다. 각 모듈은 특정 도메인 또는 비즈니스 기능을 중심으로 구성된다.
    
    - **비즈니스 중심**: 모듈이 비즈니스 도메인에 따라 구성되어, 비즈니스 요구사항과 밀접하게 연관된다.
    - **전문성 강화**: 각 도메인에 대한 전문성을 가진 팀이 모듈을 관리할 수 있다.
    - 장점:
        - 비즈니스 친화성
        - 유지보수 용이성
        - 확장성
    - 단점:
        - 복잡성 증가: 도메인 간의 상호작용이 복잡해질 수 있으며, 이를 관리하기 위한 추가적인 노력이 필요
        - 중복 코드: 비슷한 기능이 여러 도메인에서 필요할 경우, 중복 코드가 발생할 수 있음
    
    → 애초에 모듈화의 목적은
    
    1. 코드의 복잡성 완화
    2. 사용량이 많을 것으로 예상되는 도메인을 별도로 배포할 수 있도록 함
    3. 하나의 도메인에 문제가 생기더라도 영향을 최소화하기 위함
    
    ### 따라서 도메인별로 모듈화 하기로 결정!
    
    ## 멀티 모듈로 전환 후 구조
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/3e920e06-9bd2-4fc9-add2-9fd20fcaaee7/image.png)
    
    각각이 주입받는 의존성은 다음과 같다.
    
    1. Common: 없음
    2. Service: Common, Notification
    3. User: Common
    4. Notification: Common
    5. Auction: Common, User
    6. Batch: Common, Service, User
    
    ### 서비스 모듈에 여러 도메인이 들어가있는 이유?
    
    처음부터 설계를 잘 하고 모듈화를 한 것이 아니라 프로젝트 중간부터 필요성이 느껴져 모듈화를 하다보니 도메인들이 서로 강하게 의존하고 결합된 형태가 되었다. 
    
    리팩토링까지 시간이 많이 걸릴 것으로 예상이 되며 서로 연관된 도메인들이고 Center, Fitness, Timeslot의 경우 사실상 센터 기능을 담당하는 하나의 도메인으로 봐도 될 것 같고 Club, Member, MemberApplicant 역시 마찬가지다. Schedule도 분리하고 싶었지만 Center와 Club에 의존하고 Center와 Club도 Schedule에 의존하기 때문에 하나의 모듈로 두는 것이 더 좋을 것 같다고 판단하였다. 
    
    서로 연관되어 있는 경우가 많고 공통적으로 Notification을 의존받고 있었기 때문에 이렇게 하나의 모듈로 묶게 되었다.
    
    ### 향후 도전계획
    
    도메인별 모듈화는 MSA의 원칙과 잘 맞아떨어지며, 비즈니스 도메인에 기반한 설계, 독립적인 배포, 유지보수 용이성, 기술 스택의 다양성, 테스트 용이성, 팀의 자율성 등 여러 장점을 통해 MSA의 이점을 극대화할 수 있다.
    
    따라서 각각의 모듈의 의존성을 최대한 줄이는 식으로 리팩토링하여 **MSA로 전환하는 것이 목표**이며 이러한 확장성을 노리고 도메인별 모듈화를 선택한 것도 있다. 
    
- 일정 등록(예약) 동시성 제어
    
    ## [배경]
    
    ### 이벤트성 일정이 있지 않을까? 라는 생각을 했습니다. 갑자기 김종국이 특정 체육관에서 일일 트레이너를 하는 컨텐츠를 기획해서 사람들을 모집하는 상황이 발생했다고 가정했습니다.
    
    ## [요구사항]
    
    ### 1. 김종국은 구독자가 309만 명을 보유할 정도로 인기가 많다. 따라서 위의 배경과 같은 이벤트가 발생했을 때 수 많은 사람들이 하나의 센터 하나의 운동 시간대에 일정 등록을 신청하는 상황이 발생
    
    ### 2. 김종국이 이벤트를 주최한 해당 일정은 최대 수용인원이 50명이다. 이 인원을 초과하지 않도록 동시성 제어가 필요
    
    ### 3. 테스트 시나리오: 1000명이 20초 동안 같은 일정을 등록하려는 상황
    
    ### 4. 일정 등록은 Service 모듈에 있다. Service 모듈은 오토스케일링이 가능한 분산 서버 환경이다.
    
    ### 5. 이 테스트 시나리오는 이벤트성 시나리오이기 때문에 항상 이런 경우가 있는 것은 아니다.
    
    [선택지]
    
    ### 락 종류에 대한 고민
    
    ### 1. 고민도 안하고 버린 선택지
    
    - **synchronized**: 분산 서버에서는 여러 인스턴스가 존재하므로, 한 서버에서 synchronized를 사용하더라도 다른 서버의 상태를 고려하지 못한다. 이로 인해 동기화가 제대로 이루어지지 않아 데이터 일관성이 깨질 수 있다. → stateless 하지 못하다.
    - **SERIALIZABLE**: 전체 데이터베이스를 대상으로 SERIALIZABLE이 적용되기 때문에 성능하락이 예상된다. `@Transactional(isolation = Isolation.SERIALIZABLE)` 을 사용하여 트랜잭션 단위로 SERIALIZABLE을 걸어 성능을 높인다 해도 이 설정은 쓰기만 막을 뿐 읽기는 막지 못하기 때문에 동시성제어가 되지 않는다.
    
    ### 2. 고민은 해봤지만 흠…
    
    - **낙관적 락**: 데이터 수정 시점에만 충돌을 확인하고, 충돌이 발생하지 않을 것이라고 가정하는 방식(Read Lock, Shared Lock: Read는 가능, Write는 불가)
        - 장점:
            - 락 오버헤드가 없으므로 성능이 향상된다.
            - 데드락이 발생하지 않으며, 동시성이 높은 환경에서 효율적이다.
        - 단점:
            - 충돌 발생 시 이를 처리하기 위한 추가 로직이 필요(재시도 처리)
            - 충돌이 발생할 경우 트랜잭션을 롤백해야 하므로, 충돌이 잦은 경우 성능 저하 발생
    
    → 요구사항의 테스트 시나리오에서는 1000명의 사용자가 동시에 동일한 일정을 등록하려고 하므로 충돌이 발생할 가능성이 매우 높다.
    
    ### 3. 진짜 고민
    
    - **비관적 락**: 충돌이 자주 발생한다고 가정하고 동시성을 관리하는 방법이며, 데이터에 대한 접근을 시도할 때, 다른 트랜잭션이 해당 데이터에 접근하지 못하도록 락을 걸어버리는 방식이며 트랜잭션이 완료될 때까지 유지(Write lock, Exclusive Lock: Read, Write 모두 불가)
        - 장점:
            - 데이터 충돌이 발생할 가능성이 높은 경우, 즉 여러 사용자가 동시에 동일한 데이터를 수정하려고 할 때 데이터의 일관성을 강하게 보장
            - 충돌을 사전에 방지하므로 트랜잭션 실패가 줄어듬
        - 단점:
            - 락을 기다리는 대기 시간이 발생할 수 있으며, 성능 저하가 발생
            - 많은 사용자가 동시에 접근할 경우, 락 경합이 발생하여 시스템의 응답성이 떨어짐
    
    - **분산 락**: 분산 환경에서 동일한 자원에 대한 경쟁 조건을 방지하고 데이터의 무결성을 유지하기 위해 사용한다. 일반적으로 **Redis** 등의 외부 시스템을 이용하여 구현
        - 장점:
            - 여러 인스턴스가 동시에 자원에 접근할 때 데이터의 일관성을 유지가능(공유 자원에 대한 접근을 조율)
            - 분산 환경에서의 동시성 문제를 해결하는 데 효과적(데이터 일관성과 무결성을 보장)
        - 단점:
            - 네트워크 지연이나 장애로 인해 락 흭득 및 해제의 신뢰성이 문제될 수 있음
    
    낙관적 락과 비관적 락은 공통적으로 DB에 접근하지 않는 이상 락이 걸려있는지 아닌지 확인할 수 없다. DB는 stateless 하지 않고 stateful 하기 때문에 스케일링이 힘들고 이로인해 모든 대부분의 병목 현상은 DB로부터 온다. 
    
    즉, 낙관적 락과 비관적 락의 공통적인 단점인 DB에 접근한다는 점에서 두 락은 DB에 부하를 준다. 
    
    또한, 비관적 락은 데이터 충돌이 발생할 가능성이 높은 경우에 효율이 좋지만 항상 충돌이 발생할 가능성이 높은 것은 아니다. 그리고 비관적 락은 주로 단일 데이터베이스 인스턴스에서 사용되므로 Scale Out의 어려움이 있지만, 반면에 분산 락은 여러 서버에 걸쳐 자원을 관리할 수 있어, 시스템을 Scale Out하는데 유리하다.(새로운 서버를 추가하더라도 락 메커니즘이 잘 작동)
    
    ### **따라서 성능이 좀 더 떨어지라도 분산락을 이용하기로 결정!**
    
    ### 분산 락 기술 스택 고민
    
    - **MySQL 네임드 락**:  데이터베이스 내에서 특정 이름을 가진 락을 생성하여 사용한다. (SQL 쿼리로 락을 획득하고 해제)
        - 장점:
            - MySQL을 사용중이기에 추가적인 인프라 세팅없이 구현할 수 있음
            - MySQL 자체적으로 제공하는 기능이기에 구현이 간단하고 쉬움
        - 단점:
            - 동시성 문제 발생시 DB에 많은 부하를 주게되고 성능저하가 발생
            - 데이터베이스가 분산되어 있거나 MSA 환경에서 서비스별로 DB를 분리하여 운영하는 경우 네임드 락의 정보를 공유하고 동기화하는 문제의 난이도가 매우 높아짐
            
        
        → 현재의 프로젝트 구조에서는 데이터베이스가 분산되어 있거나 MSA 환경이 아니므로 고려해볼만 한 기술이지만 이 말은 곧 확장성이 떨어진다는 의미이므로 고민이 됨
        
        → 구현이 간단하다고 하지만 락을 사용하기 위해 별도의 커넥션 풀을 관리해야하고 락에 관련된 부하를 DB에서 받는다. 따라서 락 자체에 대한 선택지의 의사결정에서 DB에 부하를 주지않기 위해 분산락을 사용했으므로 적합하지 않다고 생각
        
    
    - **Redis 분산 락**: Redis는 인메모리 데이터베이스로, 빠른 읽기/쓰기 속도를 제공한다. 또한, 키-값 저장소로서 간단한 락 구현이 가능하다.
        - 장점:
            - 기본적으로 Redis는 인메모리DB이기에 더 빠르게 락을 획득 및 해제 가능
            - 분산 락에 대한 부하를 Redis가 감당하여 DB 과부하 위험이 줄어듬
            - 분산 락 관리자 역할을 하나의 DB가 아니라 Redis가 맡음으로써 데이터베이스가 분산되어 있거나, MSA 환경에서 서비스별로 DB를 분리하여 운영하는 경우에도 문제없이 동시성 이슈 제어가 가능 → 확장성이 좋음
        - 단점:
            - 데이터가 메모리에 저장되므로, 서버 장애 시 데이터 손실 가능성이 있음
            - 데이터 일관성을 보장하기 위한 추가적인 로직이 필요할 수 있음
            - 높은 동시성 환경에서는 락 경합이 발생할 수 있으며, 이로 인해 성능 저하가 발생할 수 있음
            
        
        → Redis는 다른 도메인에서 이미 사용하고 있는 기술이기 때문에 추가적인 인프라 세팅이 필요 없고 인메모리DB이기에 빠른 성능이 매력적으로 보임
        
        → 무엇보다 DB에 가해질 부하를 Redis가 감당해주므로 분산 락을 선택했던 취지에 부합
        
    
    - **Zookeeper**: 분산 시스템을 위한 코디네이션 서비스로, znodes(데이터 노드)를 사용하여 락을 관리한다. 클라이언트는 znodes를 생성하고, 이를 통해 락을 획득하거나 해제한다.
        - 장점:
            - 강력한 일관성을 제공하며, 분산 환경에서의 데이터 동기화에 적합
            - 클러스터링을 통해 고가용성을 제공하며, 장애 발생 시에도 안정적으로 동작
            - Zookeeper는 분산 락을 위한 다양한 패턴(예: 세마포어, 분산 락)을 지원하여, 복잡한 동시성 문제를 해결
        - 단점:
            - 설정과 운영이 복잡할 수 있으며, 초기 학습 곡선이 존재
            - 추가적인 인프라 세팅 필요
        
        → 초기 학습 곡선 문제와 추가적인 인프라 세팅이 필요하므로 고려하지 않음
        
        ### 따라서 Redis를 사용하기로 결정!
        
    
    [회고]
    	- 기술의 장단점
    	- 다시 시도한다면?
    
    ### Redis 분산락 라이브러리 고민
    
    1. **Lettuce:** 
        - 장점:
            - Redis의 다양한 명령어를 지원하여 유연한 사용이 가능
            - Lettuce는 Netty 기반으로 비동기 및 반응형 프로그래밍을 지원하여 높은 성능을 제공
        - 단점:
            - Lettuce의 락 구현은 상대적으로 복잡할 수 있고, 사용자가 직접 관리해야 할 부분이 많음
            - Lettuce는 분산락 구현 시 `setnx`, `setex`과 같은 명령어를 이용해 지속적으로 Redis에게 락이 해제되었는지 요청을 보내는 `Spin Lock` 방식으로 동작한다. 요청이 많을수록 Redis가 받는 부하는 커지게 됨
            
    2. **Redisson: Java 기반의 Redis 클라이언트로, 분산 락을 쉽게 구현할 수 있는 API를 제공한다.**
        - 장점:
            - RLock 인터페이스를 통해 락을 획득하고 해제하는 기능을 제공
            - Pub/Sub 기능을 활용하여 락의 상태를 관리할 수 있어서 락이 해제되는 시점에 구독중인 스레드들에게 메세지를 보낸다. 스레드가 계속해서 락 획득을 위한 요청을 보내지 않아도 되니 `Spin Lock` 방식에 비해서 레디스에 부하가 덜함
            - Redisson은 `락 획득 대기시간, 락 획득 후 점유시간`에 대한 타임아웃 기능을 이미 구현해놨기 때문에 훨씬 간편하고 효율적으로 분산락 운영
        - 단점:
            - Redisson은 상대적으로 더 많은 메모리를 사용할 수 있기 때문에 규모가 큰 서비스의 경우 성능에 영향을 줄 수 있음
    
    → Lettuce의 경우 spin lock 방식으로 주기적으로 락 해제 상태를 확인하는데, 이는 위의 테스트 시나리오처럼 락 획득 요청이 많고 트래픽이 높은 상황에서는 부하가 커질 수 있다. 반면, Redisson은 락이 해제되면 대기 중인 스레드들에게 즉시 알림을 주므로 부하가 적고, 필요한 재시도에 안정적으로 대응할 수 있다.
    
    → 사용자 경험 측면에서도 딜레이를 최소화하는 것이 중요하고 특히 많은 사용자가 같은 상품에 일정에 접근할 때는 재시도가 필요할 수 있다. 이때 Redisson의 pub-sub 방식은 락 해제를 기다리는 스레드들에게 알림을 줘 spin lock보다 부하가 적고 빠르게 처리할 수 있다.
    
    ### 따라서 Redisson을 사용하기로 결정!




## 👨🏻‍🔧 트러블슈팅

- 사용자 위치 기반 센터 검색
    
    ### 💡문제인식
    
    - 사용자 중심의 위치 기반 검색 기능이 필요해짐
        - 사용자들이 **가까운 센터**를 손쉽게 찾고 예약할 수 있도록 하는 기능은 사용자 경험 개선
    - 조회 속도의 문제
        - 초기에는 단순하게 **MySQL 쿼리**를 사용하여 모든 센터 데이터를 조회한 뒤, 애플리케이션 단에서 **거리 계산**을 수행.
        - 데이터베이스에서 모든 센터 데이터를 가져오는 방식은 데이터가 많아질수록 성능이 급격히 저하되었고, 사용자 요청이 많을 경우 **응답 시간이 느려지는 문제**가 발생
    - 확장성 문제
        - **실시간으로 위치를 기반으로 검색**해야 하기 때문에, 대용량 데이터를 빠르게 처리할 수 있는 솔루션이 필요!
    
    ### 🔎 의사결정 과정
    
    - **MySQL vs Redis vs Elasticsearch 비교 분석**
        - **MySQL**:
            - MySQL은 공간 데이터를 처리할 수 있는 **Geometry 데이터 타입**과 **SPATIAL INDEX**를 제공.
            - 하지만, 거리 계산을 위한 쿼리(`ST_Distance_Sphere`)는 대용량 데이터에서 성능이 저하되고, **실시간 조회**에서는 한계.
        - **Redis (GeoSpatial)**:
            - Redis는 **GeoSpatial 기능**을 통해 **위도/경도 기반 반경 검색**을 빠르게 처리할 수 있다(`GEOSEARCH`, `GEORADIUS`).
            - 메모리 기반으로 동작하므로, 조회 속도가 매우 빠르며, **캐싱 기능**도 제공하여 자주 조회되는 위치 데이터를 빠르게 반환할 수 있다.
        - **Elasticsearch**:
            - Elasticsearch는 `Geo-Distance Query`를 사용하여 특정 위치 기준으로 거리 계산을 하여 인근 센터를 빠르게 찾을 수 있습니다.
            - Elasticsearch는 **복잡한 쿼리**와 **다양한 필터링** 기능을 지원하므로, 단순한 거리 검색뿐만 아니라 **다양한 조건**을 조합하여 고급 위치 기반 검색을 수행할 수 있습니다
    - **의사 결정**:
        - 우리 프로젝트의 현재 위치 기반 검색 기능에서는 단순한 반경 검색이 주된 요구사항이고 MySQL Geometry는 복잡한 위치 기반 쿼리(다각형 검색 등)에 강점이 있지만, 이 프로젝트에서는 필요하지 않으므로 Redis의 간단한 반경 검색 기능이 적합하여 **redis를 선택**.
        - Redis의 **GeoSpatial 기능**을 사용하여 간단한 반경 검색을 구현. 이는 **빠른 조회 속도**와 **쉬운 캐싱** 덕분에 사용자 요청에 빠르게 응답.
        - 위치 기반 검색 성능을 개선하기 위해 **Redis GeoSpatial**과 **Elasticsearch Geo Query** 두 가지 솔루션을 검토.
        - 초기에는 두 기술의 속도와 성능 차이를 명확히 알 수 없었기 때문에, **두 가지 모두를 구현하고 실제 테스트를 통해 결정**.
        - 이를 통해, 각각의 기술이 제공하는 **검색 속도**, **복잡한 쿼리 처리 능력**, **확장성**을 비교하고 최적의 솔루션을 선택하기로 함!!
    
    ### 👏 개선방법
    
    - **Redis를 통한 단순 반경 검색**:
        - 초기에는 Redis를 사용하여 **간단한 반경 내 센터 검색 기능**을 구현.
        - Redis는 빠른 조회 속도와 간단한 설정 덕분에 적은 리소스로 효율적인 검색이 가능.
    - **두 가지 솔루션 비교 테스트**:
        - 사용자 요구가 다양해지고, 더 정교한 위치 기반 검색 기능이 필요해짐에 따라, **Redis와 Elasticsearch 두 가지 모두 성능을 비교**.
        - Redis는 단순한 반경 검색에서 빠른 응답 속도를 보였지만, 복잡한 필터링 조건과 공간 검색 기능이 필요한 경우 Elasticsearch의 성능이 더 우수.
    - **Elasticsearch로 전환 결정**:
        - 성능 비교 결과, Elasticsearch는 **Geo Distance Query**와 **Geo Bounding Box Query** 등의 기능을 통해 복잡한 공간 검색에서 더 나은 성능을 보여주었다.
        - 이에 따라, 최종적으로 **Elasticsearch를 위치 기반 검색의 주요 솔루션으로 선택**.
    
    ### **결론**
    
    Redis와 Elasticsearch 두 가지 솔루션을 모두 구현하고 성능을 비교한 결과, 반경 검색과 복잡한 필터링과 정교한 위치 검색 등  Elasticsearch가 더 뛰어난 성능을 보였다. 따라서 최종적으로 **Elasticsearch**를 주요 위치 기반 검색 솔루션으로 선택하여 사용자 맞춤형 검색 기능과 확장성을 동시에 확보하기로 하였다.
    
    ### ✨ Before&After
    
    ![센터 검색 그래프.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/102f3bd2-b934-44d8-9067-6aec39068299/%E1%84%89%E1%85%A6%E1%86%AB%E1%84%90%E1%85%A5_%E1%84%80%E1%85%A5%E1%86%B7%E1%84%89%E1%85%A2%E1%86%A8_%E1%84%80%E1%85%B3%E1%84%85%E1%85%A2%E1%84%91%E1%85%B3.png)
    
- config-server 설정
    
    ### 💡문제인식
    
    - Config-Server
        - 배포환경과 개발환경에 환경변수를 통합관리 할 수 있는 기능이 필요해짐
            - 사용자들이 **가까운 센터**를 손쉽게 찾고 예약할 수 있도록 하는 기능은 사용자 경험 개선
        - secretes 형상관리 불가 문제
            - githubActions에서 secret환경변수를 한번 지정하면, 어떤 값을 지정했는지 보여주지 않아, 에러가나면 해당 환경변수에 어떤 값이 들어있는지 파악하기 어려웠습니다.
        - 배포/개발 환경변수 업데이트 문제
            - local 환경에서 .env로 관리하는 환경변수와 배포 환경에서 secrets로 관리하는 환경변수를 두 곳에 모두 업데이트 해주는 것도 번거로웠고, 팀원들이 두 곳에 모두 매번 넣고있는지 확인이 어려웠습니다.
            - **[문제가 될 수 있는 사항]**
                - 1) secretes 형상관리 불가 문제
                    - 팀원들이 바쁘다보면, 로컬에 환경변수 등록하였지만, secrets에는 환경변수를 넣지 않아 배포를 담당하는 사람이 에러를 자주 만나게 될 가능성이 있습니다.
                - 2) 배포/개발 환경변수 업데이트 문제
                    - 팀원마다 갖고있는 .env파일이 달라, 어떤 팀원은 에러가나고, 어떤 분은 잘 실행되는 현상이 발생할 수 있으며, .env가 .gitignore에 등록되어있기 때문에 업데이트 내용을 팔로업하기 어려울 수 있습니다.
    
    ### 🔎 의사결정 과정
    
    - **Config-Server**:
        - 통합적으로 관리할 수 있고, 환경변수가 언제 업데이트 됐는지 팔로업할 수 있는 방법이 있을까?
        - 모듈화와 MSA에 자주 사용되는, **Config-Server** 개념을 도입하면, 환경변수를 통합적으로 관리할 수 있겠다고 판단이 되었습니다.
    - **의사 결정**:
        - 결과 : config-server가 모듈화된 우리 서비스에 잘 맞았고, 환경변수 관리가 편해졌습니다. -
        - 전후 데이터 비교 : 팀원들이 개발하기에 훨씬 편리한 환경이 되었으며, CI/CD개발자 또한 이전보다 에러를 만나는 일이 더 적게되었습니다.
    
    ### **결론**
    
    - 기술의 장단점 : 구축하기까지 시간과 노력이 걸리지만, 한번 구축하면 프로젝트가 커질수록 시간과 인력 리소스를 오히려 더 얻어낼 수 있습니다. 하지만, CI/CD개발자는 주기적으로 환경변수를 업로드 해주어야하며, 모듈이나 서비스가 늘어날 때마다 관리해주어야 합니다.
    - 다시 시도한다면? : 전체적인 인력자원과 시간적 자원을 더 얻어낼 수 있다는 점에서, config-server를 그래도 도입할 것 같습니다.
    
- 모듈화에 따른 CI/CD 설정
    
    -아래는 모듈화에 따른 CI/CD 설계를 진행하면서 만난 문제들입니다.
    
    - **문제1: Gradlew 설정 문제**
    - **문제2: Dockerfile에서의 문제 #절망의 서막 #no such file or directory**
    - **문제3: 경로설정 문제**
    
    ## **문제1 : Gradlew 설정 문제** (멀티모듈 패키지구조)
    
    !https://blog.kakaocdn.net/dn/y4SpJ/btsKBiBwOPx/TNhKXnt50ptuscR7Dp0Bo1/img.png
    
    No such file or directory
    
    이건 모듈안에 gradlew이 없어서 생긴문제인데,
    
    굳이 모듈안에 gradlew넣을 필요 없이, 루트에 있는 gradlew쓰는 명령어를 사용하여 해결하였다.
    
    !https://blog.kakaocdn.net/dn/bMrH3F/btsKBj8nY9N/VARg5HHPtRey3MOQHhSN3k/img.png
    
    ```bash
    ./gradlew :module-batch:build -x test
    ```
    
    이걸 쓰면 루트에 있는 gradlew로 모듈-배치에 들어가서 해당 모듈을 빌드해준다.
    
    ## **문제2: Dockerfile에서의 문제 #절망의 서막 #no such file or directory**
    
    -'no such file or directory' 이제 이 에러를 20번쯤 보게될것이다..
    
    - **접근 1)** 절대경로 사용
    
    !https://blog.kakaocdn.net/dn/cLUAE8/btsKBMoHDFe/1X7d4Km7krQTl6K4i95VBk/img.png
    
    !https://blog.kakaocdn.net/dn/vnGIG/btsKzMw63is/1KlATGHlo7OAayFuiiYuX0/img.png
    
    ㄴ해결되지 않았다.
    
    - **접근 2-해결책)** 'no such file or directory' 이 에러를 20번쯤 나자, 빌드 방법을 바꾸는 걸로 결정했다.
    
    !https://blog.kakaocdn.net/dn/cIfnoD/btsKz4dm7yt/WWr0sH0g5BS6wVNedbYBsK/img.png
    
    ㄴDockerfile 문제가 해결되었다.
    
    ㄴ그리고 이 방법은 '도커 멀티스테이지 빌드' 방법인데, 이미지 크기를 줄여주고, 보안을 강화시키며, 빌드시간을 줄여주는 방법이다. (과거에는 빌더패턴을 이용해서 이러한 장점들을 얻었다고 한다.)
    
    **멀티스테이지 빌드의 주요 장점:**
    
    - **이미지 크기 감소:** 빌드에 사용된 불필요한 파일이나 도구를 최종 이미지에서 제외하여 이미지 크기를 최소화합니다.
    - **보안 강화:** 개발 도구나 중간 산출물이 포함되지 않아 공격 표면을 줄일 수 있습니다.
    - **빌드 속도 향상:** 각 단계별 캐시 활용으로 중복 작업을 최소화하여 빌드 시간을 단축할 수 있습니다.
    
    멀티스테이지 빌드와 도커 컨테이너에서 어떤 구조로 만들어지는지
    
    트리형태로 보고싶다면 아래의 글을 참고해주세요.
    
    https://ilmechaju.tistory.com/130
    
    ## **문제 3 : 경로설정 문제**
    
    !https://blog.kakaocdn.net/dn/cAs9wC/btsKCfjKTbi/6yT3T6m3X9M4KaKCxHWeM1/img.png
    
    발생한 지점 : Build and Push
    
    !https://blog.kakaocdn.net/dn/ewy6mw/btsKA7mAQq5/V0KKstj9BXV3jDIykKUuf0/img.png
    
    접근 1) githubAction 서버에서는 gradle이 없는가? → 아니다. 지원된다.
    
    접근 2)
    
    !https://blog.kakaocdn.net/dn/ctSGx8/btsKBJMnpw6/csLVbaNdyA4n7c0gVs8Wbk/img.png
    
    14번줄에 echo로 해당 경로에 파일이 잘 들어있는지 출력해보며 확인한다.
    
    → .jar파일을 찾을 수 없다고 한다. 경로설정 문제가 있다고 판단했다.
    
    **결론-해결책)**
    
    !https://blog.kakaocdn.net/dn/ddNRGU/btsKCONslGz/GZqGYpMPe28bgSRkTOYOM1/img.png
    
    도커컴포즈에서 context: 를 없애니까 해결되었따.... 하.. 이게 왜 돼?
    
- 경매 입찰 동시성 제어 성능
    
    ### 💡문제인식
    
    - **동시성 문제**: 
    다수의 사용자가 동시에 입찰할 때, 동일한 상품에 대한 최종 입찰 금액이 덮어씌워지는 데이터 경합이 발생할 가능.
    - **데이터 무결성**: 
    경매 시스템에서 가장 높은 입찰 금액을 정확히 저장해야 하므로, **데이터 무결성 보장**이 필요.
    - 락 사용 시의 트레이드오프:
    락이 적용되면 데이터 무결성을 보장할 수 있지만, 동시성 문제를 해결하려는 과정에서 성능(특히 처리량)이 감소할 위험존재.
    
    ### 🔎 의사결정 과정
    
    최종 선택: 낙관적 락(Version Lock) 선택 이유
    
    1. **성능(Performance):**
        - 1,000개의 대용량 입찰 데이터를 평균 **800ms** 대의 응답 시간으로 처리, 실시간 경매 요구사항 충족.
        - 처리량(1034.7 req/sec)이 안정적이며 대규모 입찰에 적합.
    2. **데이터 무결성(Data Integrity):**
        - 동시성 환경에서도 **데이터 무결성을 보장**, 입찰 충돌 발생 시 안전하게 처리.
        - 최고 입찰가 검증 로직으로 신뢰성 향상.
        - Redis 락만 사용할 경우에는 락을 얻지 못한 요청이 실패 처리, 입찰 실패율을 증가.
    3. **입찰 처리 방식의 적합성:**
        - Redis 락은 순차적으로 요청을 처리하며, 락이 걸린 상태에서는 다른 요청을 받지 못하고 즉시 실패(Exception)를 반환.
        - 낙관적 락은 **동시에 여러 입찰 요청을 수용**할 수 있으며, 내부 로직에서 충돌을 감지해 처리.
            - 입찰 로직 내에서 최고 입찰가보다 낮은 금액을 걸러내는 방식은 경매 시스템에 더 적합하며, 빠르게 처리되는 요청 실패를 감소.
        - 결과적으로 낙관적 락은 요청이 많아도 충돌 없이 동시성을 관리하면서 경매의 안정성을 보장.
    4. **유저 경험(User Experience):**
        - Redis 락은 락이 걸린 상태에서는 다른 사용자의 요청이 즉시 실패 처리되어, 입찰 실패율이 높아지고 유저 경험에 부정적인 영향을 미칠 가능성이 큼.
        - 낙관적 락은 동시 요청을 허용하고, 요청 자체가 성공적으로 처리된 후에 입찰 금액 검증을 진행하므로, 사용자는 시스템의 원활한 처리 경험을 느낄 수 있음.
        - 이는 특히 **동시 입찰 환경에서의 스트레스 감소와 사용자 만족도 향상**으로 이어질 가능성이 높음.
    5. **경매 시스템의 특성과 일치:**
        - 경매 시스템에서는 대량의 동시 입찰을 처리해야 하고, 특정 요청이 실패하더라도 시스템 전체의 무결성과 신뢰성이 유지되어야 함.
        - Redis 락은 동시 처리 요청 수를 제한하고, 실패율을 높이는 단점이 있어 경매 시스템에는 부적합.
        - 낙관적 락은 병렬 처리 상황에서도 충돌을 감지해 데이터 무결성을 유지하고, 실패율을 최소화하여 경매 시스템에 더 적합.
    
    ### 결론
    
    낙관적 락(Version Lock)은
    
    - 대용량 입찰 데이터를 안정적으로 처리.
    - 데이터 무결성을 보장.
    - 사용자 요청이 실패하는 비율을 줄여 유저 경험(User Experience)을 크게 개선.
    - 경매 시스템의 특성과 요구 사항에 가장 부합하는 솔루션.
    
- 일정 등록 동시성 제어
    
    ## [성능 개선 / 코드 개선 요약]
    
    ### 일정 등록 요청을 처리할 때 동시성 제어를 위해 Redis 분산락을 사용했지만 동시성 제어에 실패하여 이를 수정하는 작업을 했습니다.
    
    ## [문제 정의]
    
    ### 1000명의 사용자가 20초 동안 최대 수용인원이 50명인 일정 등록 API를 요청할 때 최대 수용인원이 50명이므로 50명만이 일정을 등록할 수 있어야 하지만 실제로 DB에 저장된 일정은 100개 정도인 상황이 발생하고 있었습니다.
    
    ## [가설]
    
    ### 1. Redis 분산락 코드 자체의 문제
    
    현재 구현된 Redis 분산락 코드는 커스텀 어노테이션을 만들어 이를 활용해 락을 걸고 싶은 api의 서비스단에 해당 어노테이션을 붙여 AOP 방식으로 구현하였습니다. 코드의 재사용성과 관심사의 분리 그리고 일관성 있는 락처리를 위해 이 방식을 사용했지만 그 만큼 분산 락의 코드 자체의 복잡성은 올라갔다고 생각하여 제일 먼저 의심했습니다.
    
    ### 2. Race Condition 문제
    
    1. 1번 사용자, 2번 사용자 두 사용자가 일정 등록을 위해 api를 동시에 요청한다.
    2. client 1이 간발의 차이로 락을 먼저 선점하고 일정의 남은 인원 수를 조회하여 남은 인원이 50인 것을 확인한다.
    3. client 1이 남은 인원을 하나 차감하고 락을 해제한다.(남은 인원은 50-1=49), 하지만 이 때 트랜잭션은 커밋 되지 않은 상태이다.
    4. client 2는 락이 해제되었다는 신호를 받고 락을 흭득하고 남은 인원을 조회한다.
    5. client 1에서 남은 인원을 차감했지만 트랜잭션이 커밋되지 않은 상태이기에 client 2는 남은 인원 조회시 50으로 조회한다.
    6. client 2는 동일하게 남은 인원을 하나 차감하고 락을 해제하고 커밋 한다. (db에는 50-1=49로 남은 인원이 반영된다.)
    
    결국 두 사용자가 동시에 접근하여 남은 인원을 차감했지만 실제 DB에 차감된 남은 인원은 2명이 아닌 1명이다. 이러한 시나리오라면 일정이 50개만 등록이 된 것이 아닌 거의 일정하게 100개의 일정이 등록된 것이 그럴듯 한 상황이라는 생각이 들었습니다.
    
    ![제목 없음.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/fb312a38-4b72-4f0c-b8f4-2b1c5f06e396/%EC%A0%9C%EB%AA%A9_%EC%97%86%EC%9D%8C.png)
    
    ### 3. Transactional 어노테이션 문제
    
    트랜잭션 커밋 시점: @Transactional이 적용된 메서드가 끝나고 커밋될 때까지 데이터베이스의 상태가 변경되지 않기 때문에, 첫 번째 트랜잭션이 커밋되기 전에 두 번째 트랜잭션이 같은 데이터를 읽고 수정할 수 있는 상황이 발생할 수 있습니다.
    
    → 2번과 같은 경우이지만 @Transactional 어노테이션과 관련된 코드들을 수정해야할 것 같았습니다.
    
    ### [해결 방안]
    
    ### 1. 분산 락 로직 검증
    
    커스텀 어노테이션을 활용하여 AOP로 구현한 분산 락 코드 자체에 문제가 있을 것이라는 생각에 별도의 프로젝트를 따로 만들어서 분산 락 로직을 검증하였습니다. 별도의 프로젝트에서 실행했을 때는 정상적으로 동시성제어가 잘 되어있는 결과를 확인할 수 있었습니다.
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/50fab01f-3cc3-4066-bc0a-d10511a3898b/image.png)
    
    ### 2. 락을 해제하는 시점이 트랜잭션이 커밋된 이후인지 확인
    
    AOP 분산 락 코드 자체에는 문제가 없어보여서 AOP에서 트랜잭션 분리를 위해 만든 클래스인 AopForTransaction의 코드에서 추가적으로 트랜잭션이 성공적으로 커밋된 후에 락을 해제하도록 수정하였습니다.
    
    **before**
    
    ```java
    public Object proceed(ProceedingJoinPoint joinPoint) throws Throwable {
            TransactionStatus status = transactionManager.getTransaction(
                    new DefaultTransactionDefinition()
            );
    
            try {
                Object result = joinPoint.proceed();
                transactionManager.commit(status);
                return result;
            } catch (Exception e) {
                transactionManager.rollback(status);
                throw e;
            }
        }
    ```
    
    **after**
    
    ```java
    public Object proceed(ProceedingJoinPoint joinPoint, RLock lock) throws Throwable {
            TransactionStatus status = transactionManager.getTransaction(
                    new DefaultTransactionDefinition()
            );
    
            try {
                Object result = joinPoint.proceed();
                transactionManager.commit(status);
                return result;
            } catch (Exception e) {
                transactionManager.rollback(status);
                throw e;
            } finally {
                // 트랜잭션이 성공적으로 커밋된 후에 락을 해제
                if (lock != null && lock.isHeldByCurrentThread()) {
                    lock.unlock();
                    log.debug("Released lock - key: {}", lock.getName());
                }
            }
        }
    ```
    
    하지만 결과는 여전히 50개의 일정만 등록되는 것이 아닌 100개의 일정이 등록되고 있었습니다.
    
    ### 3. @Transactional 어노테이션 문제
    
    - @Transactional의 동작 방식:
        - @Transactional 어노테이션이 붙은 메서드는 Spring의 트랜잭션 관리에 의해 하나의 트랜잭션으로 묶입니다. 이 경우, 메서드 내에서 발생하는 모든 데이터베이스 작업은 트랜잭션이 완료될 때까지 커밋되지 않습니다. 즉, 메서드가 끝나기 전까지 다른 트랜잭션에서 해당 데이터에 접근할 수 없습니다.
        - Locking: 트랜잭션이 진행되는 동안 해당 데이터에 대한 잠금이 발생할 수 있습니다. 이로 인해 다른 트랜잭션이 해당 데이터에 접근하려고 할 때 대기 상태가 되거나, 잠금이 해제될 때까지 기다려야 합니다.
        
    
    시도한 해결 방법 1. AopForTransaction 클래스에 분산 락을 별도의 트랜잭션에서 실행하기 위해 
    `@Transactional(propagation = Propagation.*REQUIRES_NEW*)` 작성
    
    ```java
       	@Transactional(propagation = Propagation.REQUIRES_NEW)
        public Object proceed(ProceedingJoinPoint joinPoint) throws Throwable {
            TransactionStatus status = transactionManager.getTransaction(
                    new DefaultTransactionDefinition()
            );
    
            try {
                Object result = joinPoint.proceed();
                transactionManager.commit(status);
                return result;
            } catch (Exception e) {
                transactionManager.rollback(status);
                throw e;
            }
        }
    ```
    
    REQUIRES_NEW를 통해서 별도의 트랜잭션으로 분리하려 했지만 이 경우 TPS가 2정도로 진짜 최악의 성능을 보여줍니다.
    
    시도한 해결 방법 2. 일정 등록 메서드에서 @Transactional 어노테이션 삭제
    
    **before**
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/fdaf9741-bea6-4340-894d-fc4ed39cd201/image.png)
    
    **after**
    
    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/83c75a39-3aba-4ba4-a792-7aefe4b07895/9c3bf42f-1574-4d3b-8795-bc411d5e680b/image.png)
    
    최대 수용 인원인 50개의 일정만 등록된 것을 볼 수 있다.
    
    ## [결론]
    
    - @Transactional을 제거하면, 메서드 내의 데이터베이스 작업이 개별적으로 실행됩니다. 이 경우, 각 호출은 독립적으로 처리되며, 데이터베이스에 대한 접근이 즉시 이루어집니다. 따라서 다음과 같은 장점이 있습니다:
        - 즉각적인 데이터 업데이트: 각 일정 등록이 완료되면 데이터베이스에 즉시 반영되므로, 다른 트랜잭션이 최신 상태의 데이터를 확인할 수 있음
        - 경쟁 조건 회피: 만약 @Transactional이 없으면, 각 사용자가 예약을 시도할 때 이미 업데이트된 최대 인원 수를 확인할 수 있으므로, 레이스 컨디션이 발생할 가능성이 줄어듬
        
    
    → 결론적으로, @Transactional을 사용하면 트랜잭션의 일관성을 보장할 수 있지만, 동시에 여러 사용자가 같은 자원에 접근할 때 레이스 컨디션이 발생할 수 있습니다. 반면, @Transactional을 제거하면 각 호출이 독립적으로 처리되어 레이스 컨디션을 피할 수 있지만, 데이터의 일관성을 보장하기 어려울 수 있습니다. 
    
    ### 따라서, 동시성 제어를 위해서는 적절한 잠금 메커니즘이나 다른 동시성 제어 기법을 사용하는 것이 중요
    
    ## [회고]
    
    동시성 제어에 실패해서 트러블 슈팅을 진행하던 도중 비관 락과 분산 락을 같이 쓰는 경우도 있다는 사실을 알게되었습니다. 
    
    ### 두 가지 락을 조합하는 경우의 장단점
    
    **장점:** 
    
    - **성능과 안정성 향상**
        - DB 단의 비관적 락이 로컬 트랜잭션의 동시성을 제어하고, Redis가 분산 환경에서의 동시성을 제어하여 이중 안전장치 역할을 함
        - Redis의 인메모리 특성으로 인해 락 획득/해제가 빠르게 처리됨
        - Redisson을 사용할 경우 pub/sub 방식으로 구현되어 Redis 서버 부하를 줄일 수 있음
    - **유연한 락 관리**
        - 분산 락 관리를 Redis가 전담하므로 DB 부하가 감소
        - MSA 환경이나 분산 DB 환경에서도 효과적인 동시성 제어가 가능
    
    **단점:**
    
    - **복잡성 증가**
        - 두 가지 락 매커니즘을 관리해야 하므로 시스템 복잡도가 증가
        - 락 획득 실패 시 재시도 로직 구현이 필요
    - **리소스 사용 증가**
        - Redis 서버 관리에 추가적인 인프라 비용이 발생
        - 메모리 최적화, 장애 복구, 데이터 일관성 유지 등 추가적인 관리가 필요
    
    → 비관 락과 분산 락을 조합하여 구현하였을 경우 확실히 동시성 제어에는 탁월했지만 혹시나 하는 마음에 분산 락을 걸어주는 커스텀 어노테이션을 제거했을 때도 동시성 제어가 잘 되는 모습이었습니다. 그냥 단순히 비관 락 때문에 잘 작동했던 것은 아닌지 혹은 분산 락의 의미가 없어지는 것이 아닌지 하는 생각이 들어 좀 더 공부가 필요할 것 같습니다.






  🧑‍💻 CONTRIBUTORS

  |팀원명|포지션|담당(개인별 기여점)|깃허브 링크|
|------|---|---------------|---------|
|이건|리더|테스트3|https://github.com/doolchong|
|이현중|부리더|테스트3|https://github.com/ilmechaJu|
|홍성현|팀원|테스트3|https://github.com/pookyspooky|
|이유진|팀원|테스트3|https://github.com/pringles1234|
|김태현|팀원|테스트3|https://github.com/tae98|
